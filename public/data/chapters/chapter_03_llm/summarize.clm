abstract:
  purpose: Summarize text using a local LLM
  description: 'Uses Ollama with gemma3:latest to generate concise summaries of input
    text.

    Demonstrates LLM runtime integration with CLM framework.

    '
  inputs:
    text:
      type: string
      description: Text to summarize
  outputs:
    summary:
      type: string
      description: Concise summary of the input
  preconditions:
  - Ollama service is running
  - Model is available
  postconditions:
  - Returns a text summary
concrete:
  runtime: llm
  provider: ollama
  model: gemma3:latest
  llm_config:
    system_prompt: "You are a concise summarizer. When given text, provide a brief\
      \ 1-2 sentence \nsummary that captures the key points. Be direct and avoid filler\
      \ words.\n"
    temperature: 0.3
    max_tokens: 200
    response_format: text
  input_type: mcard
  output_type: mcard
  process_type: custom
balanced:
  test_cases:
  - given: "The Cubical Logic Model (CLM) is a three-dimensional verification framework\
      \ \nthat ensures consistency between Abstract specifications, Concrete implementations,\
      \ \nand Balanced expectations. It provides mathematical guarantees for code\
      \ correctness.\n"
    when:
      operation: summarize
    then:
      result_contains: verification
  expectations:
    performance:
      max_time_ms: 60000
    quality:
      coherence: high
